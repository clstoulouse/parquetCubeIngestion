fr.cls.bigdata.metoc.netcdf.crawler {
  # if false iterate over datasets folders in the order given by the dataset repository, otherwise it randomly shuffles the list before iterating
  shuffle-datasets = false
  # name of the folder where raw netcdf files will be moved while they are being processed by the crawler
  in-progress-folder-name = ".inprogress"
  on-success {
    copy-to = "" # Path to the folder where successfully processed raw netcdf files are moved, if null or empty the processed files are not moved
    remove-input-file = false # if set to true the input file is removed
  }
  on-failure {
    copy-to = "" # Path to the folder where raw netcdf files that failed to be process are moved, if null or empty the processed files are simply removed
    remove-input-file = false # if set to true the input file is removed
  }
  # time to pause between two crawling iterations
  crawling-period = "30 seconds"
  default-rounding = {
    coordinates-precision = 5
    rounding-mode = RoundUp
  }
  datasets = {
    # define here reading configuration for each dataset, example:
    # dataset-name {
    #   input-folder = "file:///input-folder/dataset-1"
    #   mode = "local"
    #   rounding = {
    #     coordinates-precision = 5
    #     rounding-mode = RoundUp
    #   }
    #   excluded-variables = ["var1", "var2"]
    # }
  }
}
